{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполнил: Матиенко А.П.\n",
    "\n",
    "Группа: ИУ5-24М\n",
    "\n",
    "Задание: Необходимо решить задачу классификации текстов, сформировав два варианта векторизации признаков - на основе CountVectorizer и на основе TfidfVectorizer. В качестве классификаторов необходимо использовать два классификатора:\n",
    "\n",
    "- KNeighborsClassifier\n",
    "\n",
    "- Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10419</th>\n",
       "      <td>18 Breathtaking Mexican Treats That Will Make ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15252</th>\n",
       "      <td>Australian federal election announced for Augu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11748</th>\n",
       "      <td>Delayed Endeavour carries Japanese lab to Inte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7242</th>\n",
       "      <td>23 Hilarious Tumblr Posts That Students Will T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13911</th>\n",
       "      <td>At Least 21 Polo Horses Are Dead; Toxin Is Sus...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6554</th>\n",
       "      <td>21 Things You Need For Your Baby If You Were I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718</th>\n",
       "      <td>2007 Twenty20 World Championship: India vs Sco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14469</th>\n",
       "      <td>Can You Pick The Right Guy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>Questions and Answers With Ramon Scruggs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8986</th>\n",
       "      <td>Bomb on Jerusalem bus kills one, over 30 injured</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target\n",
       "10419  18 Breathtaking Mexican Treats That Will Make ...       1\n",
       "15252  Australian federal election announced for Augu...       0\n",
       "11748  Delayed Endeavour carries Japanese lab to Inte...       0\n",
       "7242   23 Hilarious Tumblr Posts That Students Will T...       1\n",
       "13911  At Least 21 Polo Horses Are Dead; Toxin Is Sus...       0\n",
       "...                                                  ...     ...\n",
       "6554   21 Things You Need For Your Baby If You Were I...       1\n",
       "1718   2007 Twenty20 World Championship: India vs Sco...       0\n",
       "14469                         Can You Pick The Right Guy       1\n",
       "5226            Questions and Answers With Ramon Scruggs       0\n",
       "8986    Bomb on Jerusalem bus kills one, over 30 injured       0\n",
       "\n",
       "[32000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_dirname = './datasets/'\n",
    "if os.path.exists(datasets_dirname) == 0:\n",
    "    os.mkdir(datasets_dirname)\n",
    "    \n",
    "with gzip.open(datasets_dirname + 'clickbait_data.gz', 'rb') as f_in:\n",
    "    with open(datasets_dirname + 'clickbait_data.txt', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "        \n",
    "with gzip.open(datasets_dirname + 'non_clickbait_data.gz', 'rb') as f_in:\n",
    "    with open(datasets_dirname + 'non_clickbait_data.txt', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "        \n",
    "clickbait = pd.read_csv(datasets_dirname + 'clickbait_data.txt', delimiter='__label__ ', header=None, names=['text'])\n",
    "clickbait['target'] = 1\n",
    "clickbait\n",
    "\n",
    "non_clickbait = pd.read_csv(datasets_dirname + 'non_clickbait_data.txt', delimiter='__label__ ', header=None, names=['text'])\n",
    "non_clickbait['target'] = 0\n",
    "\n",
    "df = pd.concat([clickbait, non_clickbait], axis=0)\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "df.to_csv(datasets_dirname + 'dataset.csv', index=False)\n",
    "os.remove(datasets_dirname + 'clickbait_data.txt')\n",
    "os.remove(datasets_dirname + 'non_clickbait_data.txt')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<32000x22761 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 283201 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfv = TfidfVectorizer()\n",
    "tfidf_ngram_features = tfidfv.fit_transform(df['text'])\n",
    "tfidf_ngram_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<32000x22761 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 283201 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvec = CountVectorizer()\n",
    "countvec_ngram_features = countvec.fit_transform(df['text'])\n",
    "countvec_ngram_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighboursClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9738    0.9042    0.9377      4844\n",
      "           1     0.9091    0.9752    0.9410      4756\n",
      "\n",
      "    accuracy                         0.9394      9600\n",
      "   macro avg     0.9414    0.9397    0.9393      9600\n",
      "weighted avg     0.9417    0.9394    0.9393      9600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TFIDF + KNC\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_ngram_features, df['target'], test_size=0.3, random_state=1)\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=4, target_names=list(map(str, list(y_test.unique())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8684    0.7725    0.8177      4844\n",
      "           1     0.7917    0.8808    0.8339      4756\n",
      "\n",
      "    accuracy                         0.8261      9600\n",
      "   macro avg     0.8301    0.8266    0.8258      9600\n",
      "weighted avg     0.8304    0.8261    0.8257      9600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CountVec + KNC\n",
    "X_train, X_test, y_train, y_test = train_test_split(countvec_ngram_features, df['target'], \n",
    "                                                    test_size=0.3, random_state=1)\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=4, target_names=list(map(str, list(y_test.unique())))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9875    0.9449    0.9657      4844\n",
      "           1     0.9462    0.9878    0.9666      4756\n",
      "\n",
      "    accuracy                         0.9661      9600\n",
      "   macro avg     0.9669    0.9663    0.9661      9600\n",
      "weighted avg     0.9670    0.9661    0.9661      9600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TFIDF + CNB\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_ngram_features, df['target'], test_size=0.3, random_state=1)\n",
    "model = ComplementNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=4, target_names=list(map(str, list(y_test.unique())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9851    0.9525    0.9685      4844\n",
      "           1     0.9532    0.9853    0.9690      4756\n",
      "\n",
      "    accuracy                         0.9688      9600\n",
      "   macro avg     0.9691    0.9689    0.9687      9600\n",
      "weighted avg     0.9693    0.9688    0.9687      9600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CountVec + CNB\n",
    "X_train, X_test, y_train, y_test = train_test_split(countvec_ngram_features, df['target'], \n",
    "                                                    test_size=0.3, random_state=1)\n",
    "model = ComplementNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=4, target_names=list(map(str, list(y_test.unique())))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы:\n",
    "1. TfidfVectorizer показал лучший результат в обоих моделях\n",
    "\n",
    "2. Complement Naive Bayes показал лучший результат по сравнению с Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove('datasets/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
